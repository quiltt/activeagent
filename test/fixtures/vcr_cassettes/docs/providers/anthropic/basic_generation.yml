---
http_interactions:
- request:
    method: post
    uri: https://api.anthropic.com/v1/messages
    body:
      encoding: UTF-8
      string: '{"model":"claude-sonnet-4-5-20250929","messages":[{"role":"user","content":"What
        is the Model Context Protocol?"}],"max_tokens":4096,"system":"You are a helpful
        AI assistant."}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - Ruby
      Host:
      - api.anthropic.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 1.12.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.7
      Content-Type:
      - application/json
      Anthropic-Version:
      - '2023-06-01'
      X-Api-Key:
      - ACCESS_TOKEN
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '176'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Sat, 25 Oct 2025 00:28:40 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Anthropic-Ratelimit-Input-Tokens-Limit:
      - '30000'
      Anthropic-Ratelimit-Input-Tokens-Remaining:
      - '30000'
      Anthropic-Ratelimit-Input-Tokens-Reset:
      - '2025-10-25T00:28:34Z'
      Anthropic-Ratelimit-Output-Tokens-Limit:
      - '8000'
      Anthropic-Ratelimit-Output-Tokens-Remaining:
      - '8000'
      Anthropic-Ratelimit-Output-Tokens-Reset:
      - '2025-10-25T00:28:42Z'
      Anthropic-Ratelimit-Requests-Limit:
      - '50'
      Anthropic-Ratelimit-Requests-Remaining:
      - '49'
      Anthropic-Ratelimit-Requests-Reset:
      - '2025-10-25T00:28:33Z'
      Anthropic-Ratelimit-Tokens-Limit:
      - '38000'
      Anthropic-Ratelimit-Tokens-Remaining:
      - '38000'
      Anthropic-Ratelimit-Tokens-Reset:
      - '2025-10-25T00:28:34Z'
      Request-Id:
      - req_011CUSyE8NwBnuqCnQj5dsSy
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      Anthropic-Organization-Id:
      - 2557c2f2-bcfa-4054-9fa8-ae13b3b47d6b
      X-Envoy-Upstream-Service-Time:
      - '7596'
      Via:
      - 1.1 google
      Cf-Cache-Status:
      - DYNAMIC
      X-Robots-Tag:
      - none
      Server:
      - cloudflare
      Cf-Ray:
      - 993d982f8a22eb21-SJC
    body:
      encoding: ASCII-8BIT
      string: '{"model":"claude-sonnet-4-5-20250929","id":"msg_01VZFSszA17W71Qkdi7co7Jn","type":"message","role":"assistant","content":[{"type":"text","text":"The
        Model Context Protocol (MCP) is an open protocol developed by Anthropic that
        standardizes how AI applications interact with external data sources and tools.\n\n##
        Key Features:\n\n**Purpose**: MCP enables AI assistants (like Claude) to securely
        connect to various data sources - local files, databases, APIs, and other
        services - in a standardized way.\n\n**Architecture**: It uses a client-server
        model where:\n- **MCP Hosts** (like Claude Desktop or IDEs) act as clients\n-
        **MCP Servers** provide context and tools to the AI\n- Communication happens
        via standard protocols (stdio, HTTP with SSE)\n\n**Main Benefits**:\n1. **Standardization**:
        One protocol instead of custom integrations for each data source\n2. **Security**:
        Built-in privacy and security controls\n3. **Composability**: Can connect
        multiple servers simultaneously\n4. **Flexibility**: Works with local and
        remote resources\n\n**Common Use Cases**:\n- Connecting to databases (PostgreSQL,
        SQLite)\n- Accessing file systems\n- Integrating with business tools (Slack,
        Google Drive)\n- Fetching web content\n- Interacting with development tools
        (Git, Docker)\n\nThe protocol is open-source and designed to create an ecosystem
        where developers can build MCP servers that work with any MCP-compatible AI
        application."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":21,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":0},"output_tokens":297,"service_tier":"standard"}}'
  recorded_at: Sat, 25 Oct 2025 00:28:40 GMT
recorded_with: VCR 6.3.1
