---
http_interactions:
- request:
    method: post
    uri: https://api.anthropic.com/v1/messages
    body:
      encoding: UTF-8
      string: '{"model":"claude-sonnet-4-5-20250929","messages":[{"role":"user","content":"What
        is the Model Context Protocol?"}],"max_tokens":4096,"system":"You are a helpful
        AI assistant."}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - Ruby
      Host:
      - api.anthropic.com
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 1.12.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.4.7
      Content-Type:
      - application/json
      Anthropic-Version:
      - '2023-06-01'
      X-Api-Key:
      - ACCESS_TOKEN
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '176'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Wed, 22 Oct 2025 17:19:08 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Anthropic-Ratelimit-Input-Tokens-Limit:
      - '30000'
      Anthropic-Ratelimit-Input-Tokens-Remaining:
      - '30000'
      Anthropic-Ratelimit-Input-Tokens-Reset:
      - '2025-10-22T17:19:01Z'
      Anthropic-Ratelimit-Output-Tokens-Limit:
      - '8000'
      Anthropic-Ratelimit-Output-Tokens-Remaining:
      - '8000'
      Anthropic-Ratelimit-Output-Tokens-Reset:
      - '2025-10-22T17:19:10Z'
      Anthropic-Ratelimit-Requests-Limit:
      - '50'
      Anthropic-Ratelimit-Requests-Remaining:
      - '49'
      Anthropic-Ratelimit-Requests-Reset:
      - '2025-10-22T17:19:00Z'
      Anthropic-Ratelimit-Tokens-Limit:
      - '38000'
      Anthropic-Ratelimit-Tokens-Remaining:
      - '38000'
      Anthropic-Ratelimit-Tokens-Reset:
      - '2025-10-22T17:19:01Z'
      Request-Id:
      - req_011CUNcrSDHD85o99JAv3ui7
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      Anthropic-Organization-Id:
      - 2557c2f2-bcfa-4054-9fa8-ae13b3b47d6b
      X-Envoy-Upstream-Service-Time:
      - '8713'
      Via:
      - 1.1 google
      Cf-Cache-Status:
      - DYNAMIC
      X-Robots-Tag:
      - none
      Server:
      - cloudflare
      Cf-Ray:
      - 992aa8349c2afaf8-SJC
    body:
      encoding: ASCII-8BIT
      string: '{"model":"claude-sonnet-4-5-20250929","id":"msg_01LVESreCzmNnCBVqd1A77TJ","type":"message","role":"assistant","content":[{"type":"text","text":"The
        Model Context Protocol (MCP) is an open protocol developed by Anthropic that
        standardizes how AI applications connect to and interact with external data
        sources and tools.\n\n## Key Features:\n\n**Purpose**: MCP provides a universal
        way for AI systems (like Claude) to securely access context from various sources
        - databases, files, APIs, etc. - without needing custom integrations for each
        data source.\n\n**Architecture**: It uses a client-server model where:\n-
        **MCP Hosts** (like Claude Desktop or IDEs) act as clients\n- **MCP Servers**
        expose data and tools through a standardized interface\n- Communication happens
        via local protocols (stdio) or remote protocols (HTTP with SSE)\n\n**Main
        Components**:\n- **Resources**: Data sources that can be read (files, database
        records, etc.)\n- **Prompts**: Reusable templates for common interactions\n-
        **Tools**: Functions the AI can invoke to perform actions\n\n## Benefits:\n\n-
        Eliminates the need for separate connectors for each data source\n- Provides
        security through controlled, local data access\n- Enables AI assistants to
        work with your specific data and workflows\n- Open standard that any application
        can implement\n\nThink of it like USB-C for AI - one standardized protocol
        that works across many different systems and data sources, rather than needing
        a different cable for each device."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":21,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":0},"output_tokens":299,"service_tier":"standard"}}'
  recorded_at: Wed, 22 Oct 2025 17:19:08 GMT
recorded_with: VCR 6.3.1
